{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f1ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "#import libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#folfer containing images from drones, sorted by name\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "from typing import List, Tuple, Optional\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3db69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, title=\"Image\", figsize=(12, 8)):\n",
    "    \"\"\"Display image with minimal text\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf0548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_side_by_side(img1, img2, title1=\"Image 1\", title2=\"Image 2\"):\n",
    "    \"\"\"Show two images side by side\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    ax1.set_title(title1, fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    ax2.set_title(title2, fontsize=14, fontweight='bold')\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5e183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_matches(img1, img2, kp1, kp2, good_matches, title=\"Feature Matches\"):\n",
    "    \"\"\"Visualize feature matches between two images\"\"\"\n",
    "    if len(good_matches) > 0:\n",
    "        img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches[:50], None,\n",
    "                                    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "        show_image(img_matches, f\"{title} ({len(good_matches)} matches)\", figsize=(16, 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fdfb6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, max_width=1200, max_height=800):\n",
    "    \"\"\"Resize image if too large\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(max_width / w, max_height / h, 1.0)\n",
    "\n",
    "    if scale < 1.0:\n",
    "        new_w = int(w * scale)\n",
    "        new_h = int(h * scale)\n",
    "        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c845b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(directory_path, supported_formats=None):\n",
    "    \"\"\"Load images from directory with minimal output\"\"\"\n",
    "    if supported_formats is None:\n",
    "        supported_formats = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "\n",
    "    print(f\"Loading images from: {directory_path}\")\n",
    "\n",
    "    original_dir = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(directory_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return [], [], {}\n",
    "\n",
    "    # Find image files\n",
    "    all_files = os.listdir()\n",
    "    image_files = [f for f in all_files if any(f.lower().endswith(ext) for ext in supported_formats)]\n",
    "    path = sorted(set(image_files))\n",
    "\n",
    "    print(f\"Found {len(path)} images\")\n",
    "\n",
    "    # Load images\n",
    "    img_list = []\n",
    "    img_paths = []\n",
    "\n",
    "    for img_path in path:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = resize_image(img)\n",
    "            img_list.append(img)\n",
    "            img_paths.append(img_path)\n",
    "\n",
    "    # Show loaded images\n",
    "    if len(img_list) > 0:\n",
    "        print(f\"Successfully loaded {len(img_list)} images\")\n",
    "\n",
    "        # Display first few images\n",
    "        for i, (img, path) in enumerate(zip(img_list[:4], img_paths[:4])):\n",
    "            show_image(img, f\"Loaded Image {i+1}: {path}\")\n",
    "\n",
    "    os.chdir(original_dir)\n",
    "    return img_list, img_paths, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d7404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geometric_verification(kp1, kp2, matches, max_reproj_error=5.0):\n",
    "    \"\"\"Apply geometric verification to filter out bad matches\"\"\"\n",
    "    if len(matches) < 4:\n",
    "        return matches, None\n",
    "\n",
    "    # Extract point coordinates\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Try multiple homography estimation methods\n",
    "    methods = [\n",
    "        (cv2.RANSAC, \"RANSAC\"),\n",
    "        (cv2.LMEDS, \"LMEDS\"),\n",
    "        (cv2.RHO, \"RHO\")\n",
    "    ]\n",
    "\n",
    "    best_inlier_count = 0\n",
    "    best_mask = None\n",
    "    best_homography = None\n",
    "\n",
    "    for method, method_name in methods:\n",
    "        try:\n",
    "            H, mask = cv2.findHomography(src_pts, dst_pts, method, max_reproj_error)\n",
    "            if H is not None and mask is not None:\n",
    "                inlier_count = np.sum(mask)\n",
    "                if inlier_count > best_inlier_count:\n",
    "                    best_inlier_count = inlier_count\n",
    "                    best_mask = mask\n",
    "                    best_homography = H\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if best_mask is not None:\n",
    "        # Filter matches based on inliers\n",
    "        verified_matches = [matches[i] for i in range(len(matches)) if best_mask[i]]\n",
    "        return verified_matches, best_homography\n",
    "    else:\n",
    "        return matches, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "241e7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_consistency_check(kp1, kp2, matches, neighbor_distance=50):\n",
    "    \"\"\"Check spatial consistency of matches\"\"\"\n",
    "    if len(matches) < 10:\n",
    "        return matches\n",
    "\n",
    "    # Convert keypoints to arrays\n",
    "    pts1 = np.array([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.array([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "    consistent_matches = []\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        # Find neighbors in first image\n",
    "        distances = np.linalg.norm(pts1 - pts1[i], axis=1)\n",
    "        neighbors_idx = np.where((distances < neighbor_distance) & (distances > 0))[0]\n",
    "\n",
    "        if len(neighbors_idx) < 2:\n",
    "            consistent_matches.append(match)\n",
    "            continue\n",
    "\n",
    "        # Check if relative positions are consistent in second image\n",
    "        consistent_count = 0\n",
    "        for j in neighbors_idx:\n",
    "            # Relative position in image 1\n",
    "            rel_pos1 = pts1[j] - pts1[i]\n",
    "            # Relative position in image 2\n",
    "            rel_pos2 = pts2[j] - pts2[i]\n",
    "\n",
    "            # Check if relative positions are similar\n",
    "            if np.linalg.norm(rel_pos1 - rel_pos2) < neighbor_distance * 0.5:\n",
    "                consistent_count += 1\n",
    "\n",
    "        # Keep match if majority of neighbors are consistent\n",
    "        if consistent_count >= len(neighbors_idx) * 0.3:\n",
    "            consistent_matches.append(match)\n",
    "\n",
    "    return consistent_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26bf6859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def warpImages(img1, img2, H, upscale_factor=1.0):\n",
    "    \"\"\"Warp and blend two images using homography matrix\"\"\"\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "    # Get corner points of both images\n",
    "    corners_img1 = np.float32([[0, 0], [0, rows1], [cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "    corners_img2 = np.float32([[0, 0], [0, rows2], [cols2, rows2], [cols2, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Warp corners of img2\n",
    "    warped_corners_img2 = cv2.perspectiveTransform(corners_img2, H)\n",
    "    all_corners = np.concatenate((corners_img1, warped_corners_img2), axis=0)\n",
    "\n",
    "    # Bounding box\n",
    "    [x_min, y_min] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "    translation = [-x_min, -y_min]\n",
    "\n",
    "    # Translation homography\n",
    "    H_translation = np.array([\n",
    "        [1, 0, translation[0]],\n",
    "        [0, 1, translation[1]],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    # Warp img2\n",
    "    warped_img2 = cv2.warpPerspective(img2, H_translation @ H, (x_max - x_min, y_max - y_min), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Place img1 on top\n",
    "    warped_img2[translation[1]:translation[1]+rows1, translation[0]:translation[0]+cols1] = img1\n",
    "\n",
    "    # Crop out large black areas\n",
    "    gray = cv2.cvtColor(warped_img2, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        x, y, w, h = cv2.boundingRect(contours[0])\n",
    "        cropped = warped_img2[y:y+h, x:x+w]\n",
    "    else:\n",
    "        cropped = warped_img2\n",
    "\n",
    "    # Optional upscaling\n",
    "    # if upscale_factor > 1.0:\n",
    "    #     final = cv2.resize(cropped, None, fx=upscale_factor, fy=upscale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "    # else:\n",
    "    final = cropped\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed7fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_detectors():\n",
    "    \"\"\"Create multiple feature detectors for robust matching\"\"\"\n",
    "    detectors = {}\n",
    "\n",
    "    # SIFT - good for general purpose\n",
    "    detectors['SIFT'] = cv2.SIFT_create(nfeatures=1000, contrastThreshold=0.03, edgeThreshold=15)\n",
    "\n",
    "    # ORB - faster, good for textured scenes\n",
    "    detectors['ORB'] = cv2.ORB_create(nfeatures=1000, scaleFactor=1.2, nlevels=8)\n",
    "\n",
    "    # AKAZE - good for natural scenes\n",
    "    detectors['AKAZE'] = cv2.AKAZE_create(threshold=0.0003)\n",
    "\n",
    "    return detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecc00551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches_robust(img1, img2, match_ratio=0.75, use_multiple_detectors=True):\n",
    "    \"\"\"Enhanced feature matching with multiple strategies\"\"\"\n",
    "\n",
    "    detectors = create_multiple_detectors()\n",
    "    best_matches = []\n",
    "    best_kp1, best_kp2 = None, None\n",
    "    best_score = 0\n",
    "    best_detector = None\n",
    "\n",
    "    for detector_name, detector in detectors.items():\n",
    "        try:\n",
    "            # Detect keypoints and descriptors\n",
    "            if detector_name == 'ORB':\n",
    "                kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "                kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "                matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "                norm_type = cv2.NORM_HAMMING\n",
    "            else:\n",
    "                kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "                kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "                matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "                norm_type = cv2.NORM_L2\n",
    "\n",
    "            if desc1 is None or desc2 is None:\n",
    "                continue\n",
    "\n",
    "            # K-nearest neighbors matching\n",
    "            matches = matcher.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "            # Apply ratio test\n",
    "            good_matches = []\n",
    "            for match in matches:\n",
    "                if len(match) == 2:\n",
    "                    m, n = match\n",
    "                    if m.distance < match_ratio * n.distance:\n",
    "                        good_matches.append(m)\n",
    "\n",
    "            # Calculate match quality score\n",
    "            if len(good_matches) > 0:\n",
    "                distances = [m.distance for m in good_matches]\n",
    "                avg_distance = np.mean(distances)\n",
    "                score = len(good_matches) / (1 + avg_distance)  # More matches + lower distance = better\n",
    "\n",
    "                print(f\"{detector_name}: {len(good_matches)} matches, score: {score:.2f}\")\n",
    "\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_matches = good_matches\n",
    "                    best_kp1, best_kp2 = kp1, kp2\n",
    "                    best_detector = detector_name\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {detector_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"Best detector: {best_detector} with {len(best_matches)} matches\")\n",
    "    return best_matches, len(best_matches), best_score, best_kp1, best_kp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f54a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Robust Image Stitching with Advanced Feature Matching\n",
      "==================================================\n",
      "Loading images from: C:\\Users\\user\\Desktop\\Keshav\\RGB\n",
      "Found 60 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def stitch_images_robust(img_list: List[np.ndarray],\n",
    "                        img_paths: List[str] = None,\n",
    "                        min_match_count=8,\n",
    "                        match_ratio=0.6,  # Stricter ratio for better quality\n",
    "                        upscale_factor=1.5,\n",
    "                        show_matches_viz=True,\n",
    "                        use_geometric_verification=True,\n",
    "                        use_spatial_consistency=True):\n",
    "    \"\"\"\n",
    "    Robust image stitching with advanced feature matching\n",
    "    \"\"\"\n",
    "\n",
    "    if len(img_list) < 2:\n",
    "        print(\"Need at least 2 images\")\n",
    "        return None\n",
    "\n",
    "    img_queue = [img.copy() for img in img_list]\n",
    "    path_queue = img_paths.copy() if img_paths else [f\"image_{i}\" for i in range(len(img_list))]\n",
    "\n",
    "    stitch_count = 1\n",
    "    current_result = None\n",
    "\n",
    "    print(f\"\\nStarting robust stitching with {len(img_queue)} images...\")\n",
    "    print(f\"Using geometric verification: {use_geometric_verification}\")\n",
    "    print(f\"Using spatial consistency: {use_spatial_consistency}\")\n",
    "\n",
    "    while len(img_queue) > 1:\n",
    "        img1 = img_queue.pop(0)\n",
    "        img2 = img_queue.pop(0)\n",
    "        path1 = path_queue.pop(0) if path_queue else f\"result_{stitch_count-1}\"\n",
    "        path2 = path_queue.pop(0) if path_queue else f\"image_{stitch_count}\"\n",
    "\n",
    "        print(f\"\\n--- Step {stitch_count}: Stitching {path1} + {path2} ---\")\n",
    "\n",
    "        # Show input images\n",
    "        show_side_by_side(img1, img2, f\"Input 1: {path1}\", f\"Input 2: {path2}\")\n",
    "\n",
    "        # Find matches using robust method\n",
    "        good_matches, total_matches, match_quality, kp1, kp2 = find_matches_robust(\n",
    "            img1, img2, match_ratio\n",
    "        )\n",
    "\n",
    "        print(f\"Initial matches: {len(good_matches)}\")\n",
    "\n",
    "        # Apply spatial consistency check\n",
    "        if use_spatial_consistency and len(good_matches) > 10:\n",
    "            good_matches = spatial_consistency_check(kp1, kp2, good_matches)\n",
    "            print(f\"After spatial consistency: {len(good_matches)}\")\n",
    "\n",
    "        # Apply geometric verification\n",
    "        homography = None\n",
    "        if use_geometric_verification and len(good_matches) >= 4:\n",
    "            good_matches, homography = geometric_verification(kp1, kp2, good_matches)\n",
    "            print(f\"After geometric verification: {len(good_matches)}\")\n",
    "\n",
    "        # Show matches if requested\n",
    "        if show_matches_viz and len(good_matches) > 0:\n",
    "            show_matches(img1, img2, kp1, kp2, good_matches, f\"Step {stitch_count} - Verified Matches\")\n",
    "\n",
    "        if len(good_matches) >= min_match_count and kp1 is not None and kp2 is not None:\n",
    "            try:\n",
    "                # Use pre-computed homography or compute new one\n",
    "                if homography is None:\n",
    "                    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    homography, mask = cv2.findHomography(src_pts, dst_pts,\n",
    "                                                        cv2.RANSAC, 5.0, maxIters=5000)\n",
    "\n",
    "                if homography is not None:\n",
    "                    # Additional homography validation\n",
    "                    det = np.linalg.det(homography[:2, :2])\n",
    "                    if 0.1 < abs(det) < 10:  # Reasonable scale change\n",
    "                        # Perform stitching\n",
    "                        result = warpImages(img2, img1, homography, upscale_factor=1.0)\n",
    "                        current_result = result\n",
    "                        img_queue.insert(0, result)\n",
    "                        path_queue.insert(0, f\"stitched_step_{stitch_count}\")\n",
    "\n",
    "                        print(f\" Success! Homography determinant: {det:.3f}\")\n",
    "\n",
    "                        # Show result\n",
    "                        show_image(result, f\"Step {stitch_count} - Robust Stitched Result\")\n",
    "                    else:\n",
    "                        raise Exception(f\"Invalid homography (det={det:.3f})\")\n",
    "                else:\n",
    "                    raise Exception(\"Homography computation failed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\" Failed: {str(e)}\")\n",
    "                # Fallback strategy\n",
    "                if current_result is not None:\n",
    "                    img_queue.insert(0, current_result)\n",
    "                    path_queue.insert(0, f\"previous_result\")\n",
    "                else:\n",
    "                    better_img = img1 if img1.shape[0] * img1.shape[1] > img2.shape[0] * img2.shape[1] else img2\n",
    "                    better_path = path1 if img1.shape[0] * img1.shape[1] > img2.shape[0] * img2.shape[1] else path2\n",
    "                    img_queue.insert(0, better_img)\n",
    "                    path_queue.insert(0, better_path)\n",
    "        else:\n",
    "            print(f\" Insufficient verified matches (need {min_match_count})\")\n",
    "            # Fallback strategy\n",
    "            if current_result is not None:\n",
    "                img_queue.insert(0, current_result)\n",
    "                path_queue.insert(0, f\"previous_result\")\n",
    "            else:\n",
    "                better_img = img1 if img1.shape[0] * img1.shape[1] > img2.shape[0] * img2.shape[1] else img2\n",
    "                better_path = path1 if img1.shape[0] * img1.shape[1] > img2.shape[0] * img2.shape[1] else path2\n",
    "                img_queue.insert(0, better_img)\n",
    "                path_queue.insert(0, better_path)\n",
    "\n",
    "        stitch_count += 1\n",
    "        gc.collect()\n",
    "\n",
    "    # Final result\n",
    "    if len(img_queue) == 1:\n",
    "        final_result = img_queue[0]\n",
    "\n",
    "        # Apply final upscaling\n",
    "        if upscale_factor > 1.0:\n",
    "            print(f\"Applying final upscaling ({upscale_factor}x)\")\n",
    "            final_result = cv2.resize(final_result, None,\n",
    "                                    fx=upscale_factor, fy=upscale_factor,\n",
    "                                    interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        print(f\"\\n ROBUST STITCHING COMPLETE! Final size: {final_result.shape}\")\n",
    "        return final_result\n",
    "    else:\n",
    "        print(\" Robust stitching failed\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution with robust feature matching\"\"\"\n",
    "\n",
    "    # Set your directory path here\n",
    "    custom_dir = r'C:\\Users\\user\\Desktop\\Keshav\\RGB'  # <-- Change this path\n",
    "\n",
    "    print(\" Robust Image Stitching with Advanced Feature Matching\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "\n",
    "    # Load images\n",
    "    img_list, img_paths, _ = load_images_from_directory(custom_dir)\n",
    "\n",
    "    if len(img_list) < 2:\n",
    "        print(f\" Need at least 2 images (found {len(img_list)})\")\n",
    "        return\n",
    "\n",
    "    # Perform robust stitching\n",
    "    final_panorama = stitch_images_robust(\n",
    "        img_list=img_list,\n",
    "        img_paths=img_paths,\n",
    "        min_match_count=10,  # Slightly higher requirement\n",
    "        match_ratio=0.6,     # Stricter ratio for better quality matches\n",
    "        upscale_factor=1.5,\n",
    "        show_matches_viz=True,\n",
    "        use_geometric_verification=True,   # Enable geometric verification\n",
    "        use_spatial_consistency=True       # Enable spatial consistency check\n",
    "    )\n",
    "\n",
    "    # Show and save final result\n",
    "    if final_panorama is not None:\n",
    "        show_image(final_panorama, \"ðŸ† FINAL ROBUST PANORAMA\", figsize=(16, 10))\n",
    "\n",
    "        # Save result\n",
    "        cv2.imwrite(\"robust_panorama.jpg\", final_panorama)\n",
    "        print(\" Saved: robust_panorama.jpg\")\n",
    "    else:\n",
    "        print(\" Could not create panorama with robust matching\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
